- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Harish Kesava Rao
    - name: Languages
      value: English

- title: Education
  type: time_table
  contents:
    - title: Master of Science
      institution: University of Arizona, Tucson, AZ, USA
      year: 2011
      description:
        - Major in Management Information Systems.
        - Nationally, number 1 public graduate information systems program.
        - title: Courses
          contents:
            - Enterprise Data Management
            - Business Intelligence
            - Business Communication
            - Web Mining and Analytics
            - Data Mining
            - Software Design Patterns
            - Operations Management
    - title: Bachelor of Technology
      institution: Anna University
      year: 2007
      description:
        - Major in Information Technology.

- title: Experience
  type: time_table
  contents:
    - title: Principal Data Engineer
      institution: Atlassian
      year: 2024 - Present
      description:
        - Planning the short-term and long-term technology roadmap for Data Engineering projects. 
        - Guiding Data Engineers and Lead Data Engineers on design, data architecture for mutliple streams.
        - Resolving ambiguity and arriving at clear, actionable decisions; Help achieve trade-offs between velocity and quality.
        - Providing constructive and clear feedback during code reviews and design reviews.
        - Helping the team succeed in building robust, scalable, auditable pipelines to create a performant Data Lake on AWS (ECS, S3, Airflow), Airflow and Databricks.
        - title: Key areas/skills.
          contents:
            - Databricks
            - Delta lake storage
            - AWS - S3, SQS, SNS, Kinesis
            - Spark - Batch, performance tuning
            - DBT, Jinja templates
    - title: Staff Software Engineer/Team Lead, Data Engineering
      institution: Databricks
      year: 2022 - 2024
      description:
        - Managing multiple large-scale Data Engineering initiatives. Mentoring and advising Data Engineers.
        - Deploying data pipelines and associated resources on AWS, Azure via Terraform (HCL) on Databricks workspaces.
        - Creating spark ingestion notebooks, tuning streaming and batch spark jobs and clusters on Azure and AWS.
        - Ingesting data from REST APIs and storing them on AWS S3 via standard Python frameworks.
        - title: Key areas/skills.
          contents:
            - Databricks
            - Delta lake
            - AWS - S3, SQS, SNS, Kinesis, CodeBuild
            - Azure - Storage Blob, Eventgrid, Eventhubs
            - Spark - Streaming, batch, performance tuning
            - Terraform - resource management automation for Databricks, AWS and Azure resources.
            - Parquet, JSON file management
            - Hive metastore
    - title: Senior Data Engineer
      institution: Salesforce
      year: 2021 - 2022
      description:
        - Augment Tableau's license lifecycle analysis with AWS compute and storage alongside Snowflake.
        - title: Key areas/skills.
          contents:
            - AWS - S3, EMR, Pyspark.
            - Snowflake
            - Tableau integration with Python.
    - title: Senior Data Engineer
      institution: Amazon Prime Video
      year: 2020 - 2021
      description:
        - First Data Engineer for Prime Video Search.
        - Designed and implemented a Data Lake for Prime Video Search using EMR, Spark, Scala, S3, Athena, Tableau, SageMaker.
        - title: Key areas/skills.
          contents:
            - AWS - EMR, S3, SageMaker, Athena, Pyspark.
    - title: Senior Data Engineer
      institution: Indeed
      year: 2017 - 2020
      description:
        - Designed, standardized and automated DW/data pipelines using Postgres, Hive, Hadoop, Snowflake and Airflow.
        - title: Key areas/skills.
          contents:
            - Python
            - Postgres
            - Pyspark
            - Hive
            - Docker
            - Airflow
    - title: Senior ETL Engineer
      institution: Informatica
      year: 2014 - 2017
      description:
        - Developed and deployed ETL pipelines, data warehouses in Oracle, MySQL, MS SQL Server, Netezza, Teradata using Informatica.
        - Used Python to implement pipelines to consume raw/unstructured data.
        - title: Key areas/skills.
          contents:
            - Informatica PowerCenter, Data Quality, Metadata Manager, Data Replication, Big Data Edition, Cloud Edition.
            - Python
    - title: Presales Technical Consultant
      institution: Informatica
      year: 2012 - 2013
      description:
        - Product demos for prospects, technical Proof Of Concept engagements.
        - title: Key areas/skills.
          contents:
            - Informatica PowerCenter.

- title: Open Source Projects
  type: time_table
  contents:
    - title: Contributions to Apache Airflow
      year: 2021 - now
      description: Contributions to various providers in Airflow.

