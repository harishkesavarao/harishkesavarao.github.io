---
layout: post
title: Deploying on-premise big data pipelines.
date: 2019-11-23 08:18:00
description: Deploying big data pipelines in an on-premise Hadoop cluster.
related_posts: false
tags: bigdata data-engineering hive airflow python
featured: true
---

# On-premise big data deployment. #

## Introduction ##
This post is about a big data deployment we (myself and a few others in my company) did a few years ago. This was a time when only a few companies were cloud-first. Some of them hadn't ventured into the cloud at all and cloud adoption (mainly AWS at the time) was divided into part on-premise/part cloud to completely on-premise. 

This makes for some interesting choices for the tech stack. For instance, compute and storage had to be carefully managed. Permissions had to be manually handled as well.

## Use case and background ##
Prior to this exercise, most of our datawarehouse was on Postgres (again an on-premise deployment). That worked for a few years until the data volume grew from GB/week or month to TB/month or GB/day or week. We had to start exploring alternatives which were:
1. Scalable.
2. Maintainable.
3. Performant for the volume of data.
4. Aligned with the overall stack being used by the company at the time.
5. Proven to be effective via a Proof Of Concept.

After exploring many such alternatives and discussions with teams having similar use cases, we decided on the following:

### Tech stack ###
Almost all of the tools/technology used is Open Source, except the Hadoop cluster, deployed via Cloudera.
- **Compute:** Docker on Hadoop
- **Storage:** HDFS 
- **Orchestration:** Apache Airflow 
- **Analytics:** Presto on Hive with Spark compute (wrapper on Hive)
- **Language:** Python 2.7 at the time and then later 3.x
- **CI/CD:** Custom-built Airflow operators to handle various tasks.

## Architecture ##

## Implementation ## 

### Design decisions ###

### Compute ###
The Hadoop cluster was already available and only permissions had to be created via Hadoop Admins.

### Storage ###
HDFS with a Hive metastore.

### Orchestration and workflow management ###
We were using it previously for Postgres operators and managing table dependencies.
#### Operators ####
Custom-built airflow operators for Python, shell, docker, etc.

#### CI/CD ####

## Consumption and analytics ##

## Learning ##
### Maintenance ###

## Conclusion ## 


