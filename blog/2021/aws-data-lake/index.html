<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Building a data lake on Amazon Web Services. | Harish Kesava Rao</title> <meta name="author" content="Harish Kesava Rao"> <meta name="description" content="Building and deploying a data lake on AWS infrastructure."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="http://harishkesavarao.github.io//blog/2021/aws-data-lake/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Harish Kesava Rao</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Building a data lake on Amazon Web Services.</h1> <p class="post-meta">June 1, 2021</p> <p class="post-tags"> <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/bigdata"> <i class="fas fa-hashtag fa-sm"></i> bigdata</a>   <a href="/blog/tag/aws"> <i class="fas fa-hashtag fa-sm"></i> aws</a>   <a href="/blog/tag/data-engineering"> <i class="fas fa-hashtag fa-sm"></i> data-engineering</a>   <a href="/blog/tag/scala"> <i class="fas fa-hashtag fa-sm"></i> scala</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h1"> <a href="#introduction">Introduction</a> <ul> <li class="toc-entry toc-h2"> <a href="#pre-requisite-reading">Pre-requisite reading</a> <ul> <li class="toc-entry toc-h3"><a href="#advanced-reading">Advanced reading</a></li> <li class="toc-entry toc-h3"><a href="#infrastructure-as-code-iac">Infrastructure as Code (IaC)</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#what-is-a-data-lake">What is a Data Lake?</a></li> </ul> </li> <li class="toc-entry toc-h1"><a href="#use-cases">Use cases</a></li> <li class="toc-entry toc-h1"> <a href="#data-sources">Data sources</a> <ul> <li class="toc-entry toc-h2"> <a href="#aws-s3">AWS S3</a> <ul> <li class="toc-entry toc-h3"><a href="#cross-account-storage">Cross-account storage</a></li> <li class="toc-entry toc-h3"><a href="#data-ingestion-between-source-and-destination-aws-s3-buckets">Data ingestion between source and destination AWS S3 buckets</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#aws-kinesis">AWS Kinesis</a></li> </ul> </li> <li class="toc-entry toc-h1"> <a href="#design-decisions-trade-offs">Design decisions, trade-offs</a> <ul> <li class="toc-entry toc-h2"><a href="#compute">Compute</a></li> <li class="toc-entry toc-h2"> <a href="#storage">Storage</a> <ul> <li class="toc-entry toc-h3"><a href="#s3">S3</a></li> <li class="toc-entry toc-h3"><a href="#lifecycle-management">Lifecycle management</a></li> <li class="toc-entry toc-h3"><a href="#security">Security</a></li> <li class="toc-entry toc-h3"><a href="#cost-planning-and-optimization">Cost planning and optimization</a></li> </ul> </li> </ul> </li> <li class="toc-entry toc-h1"> <a href="#etl">ETL</a> <ul> <li class="toc-entry toc-h2"><a href="#batch-vs-streaming">Batch vs. Streaming</a></li> </ul> </li> <li class="toc-entry toc-h1"><a href="#monitoring-and-alerting">Monitoring and Alerting</a></li> <li class="toc-entry toc-h1"><a href="#analytics">Analytics</a></li> <li class="toc-entry toc-h1"><a href="#conclusion">Conclusion</a></li> </ul> </div> <hr> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <h2 id="pre-requisite-reading">Pre-requisite reading</h2> <p>In order to fully understand or follow along with the article, I recommend reading some of the documents, articles and other links I have included in this section. If you have already worked on the AWS services I have listed below, you can skip this section.</p> <ul> <li><a href="https://aws.amazon.com/getting-started/cloud-essentials/" rel="external nofollow noopener" target="_blank">AWS Cloud essentials.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/amazon-web-services-cloud-platform.html?pg=cloudessentials" rel="external nofollow noopener" target="_blank">AWS Services by category.</a></li> <li><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_introduction.html" rel="external nofollow noopener" target="_blank">AWS Organizations.</a></li> <li><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts.html" rel="external nofollow noopener" target="_blank">AWS Accounts.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/compute-services.html" rel="external nofollow noopener" target="_blank">AWS Compute.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/storage-services.html" rel="external nofollow noopener" target="_blank">AWS Storage.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/analytics.html" rel="external nofollow noopener" target="_blank">AWS Analytics.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/containers.html" rel="external nofollow noopener" target="_blank">AWS Containers.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/application-integration.html" rel="external nofollow noopener" target="_blank">AWS Application Integration.</a></li> <li><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html" rel="external nofollow noopener" target="_blank">AWS IAM.</a></li> <li><a href="https://aws.amazon.com/what-is/data-lake/" rel="external nofollow noopener" target="_blank">What is a Data Lake?</a></li> </ul> <h3 id="advanced-reading">Advanced reading</h3> <ul> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/networking-services.html" rel="external nofollow noopener" target="_blank">AWS Networking Services.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/management-governance.html" rel="external nofollow noopener" target="_blank">AWS Management and Governance.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/developer-tools.html" rel="external nofollow noopener" target="_blank">AWS Developer Tools.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/aws-cost-management.html" rel="external nofollow noopener" target="_blank">Cost management in AWS.</a></li> <li><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-overview/database.html" rel="external nofollow noopener" target="_blank">AWS Databases.</a></li> </ul> <h3 id="infrastructure-as-code-iac">Infrastructure as Code (IaC)</h3> <p>All of the AWS resources discussed can be created manually via the AWS Management Console.</p> <p>In a production deployment, that is seldom the case. We typically use an <a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/infrastructure-as-code" rel="external nofollow noopener" target="_blank">Infrastructure as Code</a> deployment to manage resources. There are a few IaC options, Terraform and AWS CDK being the most popular.</p> <p>I have worked on both and there are pros and cons with both.</p> <p>AWS CDK allows many commonly used languages to define resources - such as Python, Java, TypeScript, Go, JavaScript etc. AWS CDK uses <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-whatis-concepts.html" rel="external nofollow noopener" target="_blank">AWS CloudFormation</a> behind the scenes to deploy resources. It also comes with the same limitations as <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html" rel="external nofollow noopener" target="_blank">AWS CloudFormation</a>.</p> <p>Terraform uses its own <a href="https://developer.hashicorp.com/terraform/language" rel="external nofollow noopener" target="_blank">configuration language</a> across different clouds, which is convenient if you have a multi-cloud infrastructure. It might take some time to learn Terraform’s configuration language, but isn’t that difficult as you begin creating and deploying different resources to AWS (or to any other cloud for that matter). Terraform uses declarative syntax as opposed to other common programming langauges.</p> <p>To illustrate resource creation in this article, I will use Terraform examples for resource creation.</p> <h2 id="what-is-a-data-lake">What is a Data Lake?</h2> <p><a href="#pre-requisite-reading">Reading for this section: What is a Data Lake?</a></p> <blockquote> <p>A data lake is a centralized repository that allows you to store all your structured and unstructured data at any scale. You can store your data as-is, without having to first structure the data, and run different types of analytics—from dashboards and visualizations to big data processing, real-time analytics, and machine learning to guide better decisions.</p> <p><cite>– AWS Documentation.</cite></p> </blockquote> <h1 id="use-cases">Use cases</h1> <p>It is cost effective and performant to build a Data Lake when the data volume is over a certain threshold. The threshold is usually in the tens of GBs of data per day and continues to accumulate over time. If the data volume is less than that, it would be quicker and cheaper to build a traditional data warehouse or other solutions.</p> <p>As we saw above, a Data Lake is a centralized repository which stores all of the structured and unstructured data. This means that this data is available to anyone in an organization (with the relevant permissions). This could be - Data Analysts, Data Scientists, Data Engineers, Business Analysts, Product Managers, Finance or any other function. This offers a single source of truth of the data and each sub-function or department within an organization can choose to use the data as they see fit, with their own tooling for data access, analytics and visualization.</p> <h1 id="data-sources">Data sources</h1> <h2 id="aws-s3">AWS S3</h2> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html" rel="external nofollow noopener" target="_blank">AWS S3 (Simple Storage Service)</a> is one of the most common use cases of consuming data in AWS. You can read about the basics (buckets, etc.) of S3 from the documentation link.</p> <h3 id="cross-account-storage">Cross-account storage</h3> <p><a href="#pre-requisite-reading">Reading for this section: AWS Organizations and AWS Accounts</a></p> <p>Sometimes, the S3 bucket containing the data of interest may not reside in the same AWS account from which we are reading it. To begin reading data from such external AWS accounts, the required permissions need to be in place. <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-managing-access-example4.html" rel="external nofollow noopener" target="_blank">Reference article.</a></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cross-account-s3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cross-account-s3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cross-account-s3-1400.webp"></source> <img src="/assets/img/cross-account-s3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ol> <li>Role in destination account.</li> <li>Role in source/data source account.</li> <li>Trust policy in source/data source account.</li> <li>Access policy related to the source/data source account.</li> </ol> <p>Key roles and policies:</p> <ul> <li>Access policy for S3 bucket objects - defined in the source AWS account.</li> </ul> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"Version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2012-10-17"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Statement"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"Effect"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Allow"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Action"</span><span class="p">:</span><span class="w"> </span><span class="s2">"s3:GetObject"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Resource"</span><span class="p">:</span><span class="w"> </span><span class="s2">"arn:aws:s3:::DOC-EXAMPLE-BUCKET1/*"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p><cite>– AWS Docs.</cite></p> <ul> <li>Trust policy for the source AWS account, allowing the <code class="language-plaintext highlighter-rouge">sts:AssumeRole</code> action.</li> </ul> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"Version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2012-10-17"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Statement"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"Sid"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Effect"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Allow"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Principal"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"AWS"</span><span class="p">:</span><span class="w"> </span><span class="s2">"arn:aws:iam::source_account-ID:root"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"Action"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sts:AssumeRole"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p><cite>– AWS Docs.</cite></p> <ul> <li>IAM policy for the destination AWS account, that is, the AWS account which is going to read data from the source AWS account.</li> </ul> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"Version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2012-10-17"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Statement"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"Effect"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Allow"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Action"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"sts:AssumeRole"</span><span class="p">],</span><span class="w">
      </span><span class="nl">"Resource"</span><span class="p">:</span><span class="w"> </span><span class="s2">"arn:aws:iam::source_account-ID:role/examplerole"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p><cite>– AWS Docs.</cite></p> <ul> <li>Steps 2 and 3 need to be followed by 2 new IAM roles in the source and destination AWS accounts respectively and the policies need to be attached to those newly created roles.</li> </ul> <p>The corresponding Terraform code blocks to implement the above IAM role and policies.</p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_iam_role"</span> <span class="s2">"examplerole"</span> <span class="p">{</span>
  <span class="nx">name</span> <span class="p">=</span> <span class="s2">"test_role"</span>

  <span class="nx">assume_role_policy</span> <span class="p">=</span> <span class="nx">jsonencode</span><span class="p">({</span>
    <span class="nx">Version</span> <span class="p">=</span> <span class="s2">"2012-10-17"</span>
    <span class="nx">Statement</span> <span class="p">=</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="nx">Action</span> <span class="p">=</span> <span class="s2">"sts:AssumeRole"</span>
        <span class="nx">Effect</span> <span class="p">=</span> <span class="s2">"Allow"</span>
        <span class="nx">Sid</span>    <span class="p">=</span> <span class="s2">""</span>
        <span class="nx">Principal</span> <span class="p">=</span> <span class="p">{</span>
          <span class="nx">Service</span> <span class="p">=</span> <span class="s2">"s3.amazonaws.com"</span>
        <span class="p">}</span>
      <span class="p">},</span>
    <span class="p">]</span>
  <span class="p">})</span>

  <span class="nx">tags</span> <span class="p">=</span> <span class="p">{</span>
    <span class="nx">tag-key</span> <span class="p">=</span> <span class="s2">"tag-value"</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <ul> <li>Create a new IAM policy to allow access to S3 buckets.</li> </ul> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">resource</span> <span class="s2">"aws_iam_policy"</span> <span class="s2">"s3_access_policy"</span> <span class="p">{</span>
  <span class="nx">name</span>        <span class="p">=</span> <span class="s2">"s3_access_policy"</span>
  <span class="nx">path</span>        <span class="p">=</span> <span class="s2">"/"</span>
  <span class="nx">description</span> <span class="p">=</span> <span class="s2">"My test policy"</span>

  <span class="nx">policy</span> <span class="p">=</span> <span class="nx">jsonencode</span><span class="p">({</span>
    <span class="nx">Version</span> <span class="p">=</span> <span class="s2">"2012-10-17"</span>
    <span class="nx">Statement</span> <span class="p">=</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="nx">Action</span> <span class="p">=</span> <span class="p">[</span>
          <span class="s2">"s3:GetObject"</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="nx">Effect</span>   <span class="p">=</span> <span class="s2">"Allow"</span>
        <span class="nx">Resource</span> <span class="p">=</span> <span class="s2">"arn:aws:s3:::DOC-EXAMPLE-BUCKET1/*"</span>
      <span class="p">},</span>
    <span class="p">]</span>
  <span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <ul> <li>Attach the new IAM policy to the corresponding IAM role.</li> </ul> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_iam_role_policy_attachment"</span> <span class="s2">"test-attach"</span> <span class="p">{</span>
  <span class="nx">role</span>       <span class="p">=</span> <span class="nx">aws_iam_role</span><span class="p">.</span><span class="nx">examplerole</span><span class="p">.</span><span class="nx">name</span>
  <span class="nx">policy_arn</span> <span class="p">=</span> <span class="nx">aws_iam_policy</span><span class="p">.</span><span class="nx">s3_access_policy</span><span class="p">.</span><span class="nx">arn</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <h3 id="data-ingestion-between-source-and-destination-aws-s3-buckets">Data ingestion between source and destination AWS S3 buckets</h3> <p>There are many ways to transfer large volumes of data between two S3 buckets. AWS describes them very well <a href="https://repost.aws/knowledge-center/s3-large-transfer-between-buckets" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>Additionally, one other option is to setup downstream trigger jobs to run when a new event occurs in the AWS S3 bucket. We previously discussed setting up <a href="#security">notifications</a> for events in AWS S3 buckets. The same setup can be used here. Once the SNS is setup, the destination AWS account can listen to these notifications via the AWS Simple Queue Service (SQS). The implementation is discussed <a href="https://docs.aws.amazon.com/sns/latest/dg/sns-send-message-to-sqs-cross-account.html" rel="external nofollow noopener" target="_blank">here</a>. Once the message is received from the Queue, you can write your own <a href="https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/examples-sqs-messages.html#sqs-messages-receive" rel="external nofollow noopener" target="_blank">application</a> to ingest the data and write it to a destination of your choice, which could be another AWS S3 bucket or a Delta table etc.</p> <h2 id="aws-kinesis">AWS Kinesis</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kinesis-stream-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kinesis-stream-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kinesis-stream-1400.webp"></source> <img src="/assets/img/kinesis-stream.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>One of the most popular ways of sending and receiving large volumes of data is AWS Kinesis, via streaming. This is one of the most comprehensive <a href="https://d0.awsstatic.com/whitepapers/whitepaper-streaming-data-solutions-on-aws-with-amazon-kinesis.pdf" rel="external nofollow noopener" target="_blank">whitepapers</a> explaining different Kinesis use cases as well as tooling/services to consume/sink data from Kinesis.</p> <p>Since the whitepaper explains everything in detail, I will not elaborate on different options available with Kinesis.</p> <h1 id="design-decisions-trade-offs">Design decisions, trade-offs</h1> <p>We have discussed data sources at length. Now, we will talk about other areas of building the data lake, such as compute, alerting and analytics.</p> <h2 id="compute">Compute</h2> <p>When it comes to compute, there are a few design considerations:</p> <ul> <li>Do you have enough compute when your workloads need them?</li> <li>Is compute being utilized effectively or are you paying for compute when there isn’t utilization?</li> <li>Are you able to customize scaling up or down based on your workload? Is scaling causing additional overhead?</li> <li>Are there custom compute types available for different workloads - streaming, batch or maintenance jobs?</li> <li>Can you reserve compute ahead of time to reduce costs?</li> </ul> <p>If the compute is <a href="https://aws.amazon.com/serverless/" rel="external nofollow noopener" target="_blank">serverless</a>, it gives you scalability, but it comes at a cost because there is typically less flexibility in controlling the compute types and asscociated costs compared to instance based compute types.</p> <p>Going with instance based compute allows more granularity with costs, but it adds overhead with maintenance of instances, although services like AWS EMR do scale your instances based on usage in recent versions, offering a good middle ground. Smaller workloads can be run on serverless options such as AWS Lambda.</p> <p>Based on all of these considerations, you can choose whichever <a href="https://aws.amazon.com/products/compute/" rel="external nofollow noopener" target="_blank">AWS compute works</a> for your use case.</p> <h2 id="storage">Storage</h2> <h3 id="s3">S3</h3> <p>The most common storage mechanism in AWS is in S3, which works quite well for a data lake destination storage.</p> <p>Some considerations for optimized storage:</p> <ul> <li> <strong>Partitioning:</strong> Partition all data written to S3 buckets based on at least one partition - such as date, and possibly more, based on the data. This also facilitates efficient consumption/querying of data and for other downstream jobs to read the data from the data lake.</li> <li> <strong>File format:</strong> <a href="https://spark.apache.org/docs/latest/sql-data-sources.html" rel="external nofollow noopener" target="_blank">Many file formats</a> are available and supported by Spark (more on this in the <a href="#etl">ETL</a> section), of which, <a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html" rel="external nofollow noopener" target="_blank">parquet</a> seems to have a good trade-off in terms of write-throughput, compression, read-throughput. It also offers additional features such as partition discovery and schema merging/evolution, which are important for a data lake use case.</li> <li> <strong>Compression:</strong> It is important to compress files to avoid additonal costs and when storing data in S3. Parquet supports snappy, gzip, lzo, brotli, lz4, zstd types and I have found snappy to be efficient in terms of storage and retrieval.</li> </ul> <h3 id="lifecycle-management">Lifecycle management</h3> <p>You might want to consider maintenance of the objects in the S3 bucket, since the data might grow over time. This results in larger partition counts to maintain in addition to growing costs. So, it is a good practice to define a lifecycle configuration for the S3 objects.</p> <blockquote> <p>An S3 Lifecycle configuration is an XML file that consists of a set of rules with predefined actions that you want Amazon S3 to perform on objects during their lifetime.</p> <p><cite>– AWS Documentation.</cite></p> </blockquote> <p>The objects can be <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_lifecycle_configuration#creating-a-lifecycle-configuration-for-a-bucket-with-versioning" rel="external nofollow noopener" target="_blank">set</a> to either transition to another storage class or to expire after a certain time period.</p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_s3_bucket_lifecycle_configuration"</span> <span class="s2">"versioning-bucket-config"</span> <span class="p">{</span>
  <span class="c1"># Must have bucket versioning enabled first</span>
  <span class="nx">depends_on</span> <span class="p">=</span> <span class="p">[</span><span class="nx">aws_s3_bucket_versioning</span><span class="p">.</span><span class="nx">versioning</span><span class="p">]</span>

  <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">versioning_bucket</span><span class="p">.</span><span class="nx">id</span>

  <span class="nx">rule</span> <span class="p">{</span>
    <span class="nx">id</span> <span class="p">=</span> <span class="s2">"config"</span>

    <span class="nx">filter</span> <span class="p">{</span>
      <span class="nx">prefix</span> <span class="p">=</span> <span class="s2">"config/"</span>
    <span class="p">}</span>

    <span class="nx">noncurrent_version_expiration</span> <span class="p">{</span>
      <span class="nx">noncurrent_days</span> <span class="p">=</span> <span class="mi">90</span>
    <span class="p">}</span>

    <span class="nx">noncurrent_version_transition</span> <span class="p">{</span>
      <span class="nx">noncurrent_days</span> <span class="p">=</span> <span class="mi">30</span>
      <span class="nx">storage_class</span>   <span class="p">=</span> <span class="s2">"STANDARD_IA"</span>
    <span class="p">}</span>

    <span class="nx">noncurrent_version_transition</span> <span class="p">{</span>
      <span class="nx">noncurrent_days</span> <span class="p">=</span> <span class="mi">60</span>
      <span class="nx">storage_class</span>   <span class="p">=</span> <span class="s2">"GLACIER"</span>
    <span class="p">}</span>

    <span class="nx">status</span> <span class="p">=</span> <span class="s2">"Enabled"</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <h3 id="security">Security</h3> <p>Securing the objects in AWS S3 buckets is important. Some configurations to consider:</p> <ol> <li>Encryption.</li> <li>Public access block.</li> <li>Logging.</li> <li>Notifications.</li> <li>Metrics.</li> </ol> <p><strong>Encryption</strong> The option encrypts the S3 bucket and all objects inside the bucket. It is a good practice to enable this when creating the bucket to ensure all current and future objects are encrypted.</p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/default-encryption-faq.html" rel="external nofollow noopener" target="_blank">Related AWS Doc.</a></p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_kms_key"</span> <span class="s2">"mykey"</span> <span class="p">{</span>
  <span class="nx">description</span>             <span class="p">=</span> <span class="s2">"This key is used to encrypt bucket objects"</span>
  <span class="nx">deletion_window_in_days</span> <span class="p">=</span> <span class="mi">10</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"mybucket"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"mybucket"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket_server_side_encryption_configuration"</span> <span class="s2">"example"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">mybucket</span><span class="p">.</span><span class="nx">id</span>

  <span class="nx">rule</span> <span class="p">{</span>
    <span class="nx">apply_server_side_encryption_by_default</span> <span class="p">{</span>
      <span class="nx">kms_master_key_id</span> <span class="p">=</span> <span class="nx">aws_kms_key</span><span class="p">.</span><span class="nx">mykey</span><span class="p">.</span><span class="nx">arn</span>
      <span class="nx">sse_algorithm</span>     <span class="p">=</span> <span class="s2">"aws:kms"</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <p><strong>Public access block</strong> AWS recommends blocking public access of S3 objects, especially when dealing with sensitive data. It also recommends setting all 4 options to true (see below).</p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.htmls" rel="external nofollow noopener" target="_blank">Related AWS Doc.</a></p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"example"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"example"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket_public_access_block"</span> <span class="s2">"example"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">example</span><span class="p">.</span><span class="nx">id</span>

  <span class="nx">block_public_acls</span>       <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">block_public_policy</span>     <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">ignore_public_acls</span>      <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">restrict_public_buckets</span> <span class="p">=</span> <span class="kc">true</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <p><strong>Logging</strong> Allows logging of all access requests to the S3 bucket. The logs are stored in a separate S3 bucket, with appropriate permissions.</p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/ServerLogs.html" rel="external nofollow noopener" target="_blank">Related AWS Doc.</a></p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"example"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"my-tf-example-bucket"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket_acl"</span> <span class="s2">"example"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">example</span><span class="p">.</span><span class="nx">id</span>
  <span class="nx">acl</span>    <span class="p">=</span> <span class="s2">"private"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"log_bucket"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"my-tf-log-bucket"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket_acl"</span> <span class="s2">"log_bucket_acl"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">log_bucket</span><span class="p">.</span><span class="nx">id</span>
  <span class="nx">acl</span>    <span class="p">=</span> <span class="s2">"log-delivery-write"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_s3_bucket_logging"</span> <span class="s2">"example"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">example</span><span class="p">.</span><span class="nx">id</span>

  <span class="nx">target_bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">log_bucket</span><span class="p">.</span><span class="nx">id</span>
  <span class="nx">target_prefix</span> <span class="p">=</span> <span class="s2">"log/"</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <p><strong>Notifications</strong> AWS SNS can be enabled for an S3 bucket to be notified when specified events occur.</p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/EventNotifications.html" rel="external nofollow noopener" target="_blank">Related AWS Doc.</a></p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">data</span> <span class="s2">"aws_iam_policy_document"</span> <span class="s2">"topic"</span> <span class="p">{</span>
    <span class="nx">statement</span> <span class="p">{</span>
      <span class="nx">effect</span> <span class="p">=</span> <span class="s2">"Allow"</span>

      <span class="nx">principals</span> <span class="p">{</span>
        <span class="nx">type</span>        <span class="p">=</span> <span class="s2">"Service"</span>
        <span class="nx">identifiers</span> <span class="p">=</span> <span class="p">[</span><span class="s2">"s3.amazonaws.com"</span><span class="p">]</span>
      <span class="p">}</span>

      <span class="nx">actions</span>   <span class="p">=</span> <span class="p">[</span><span class="s2">"SNS:Publish"</span><span class="p">]</span>
      <span class="nx">resources</span> <span class="p">=</span> <span class="p">[</span><span class="s2">"arn:aws:sns:*:*:s3-event-notification-topic"</span><span class="p">]</span>

      <span class="nx">condition</span> <span class="p">{</span>
        <span class="nx">test</span>     <span class="p">=</span> <span class="s2">"ArnLike"</span>
        <span class="k">variable</span> <span class="p">=</span> <span class="s2">"aws:SourceArn"</span>
        <span class="nx">values</span>   <span class="p">=</span> <span class="p">[</span><span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">bucket</span><span class="p">.</span><span class="nx">arn</span><span class="p">]</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">resource</span> <span class="s2">"aws_sns_topic"</span> <span class="s2">"topic"</span> <span class="p">{</span>
    <span class="nx">name</span>   <span class="p">=</span> <span class="s2">"s3-event-notification-topic"</span>
    <span class="nx">policy</span> <span class="p">=</span> <span class="k">data</span><span class="p">.</span><span class="nx">aws_iam_policy_document</span><span class="p">.</span><span class="nx">topic</span><span class="p">.</span><span class="nx">json</span>
  <span class="p">}</span>

  <span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"bucket"</span> <span class="p">{</span>
    <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"your-bucket-name"</span>
  <span class="p">}</span>

  <span class="k">resource</span> <span class="s2">"aws_s3_bucket_notification"</span> <span class="s2">"bucket_notification"</span> <span class="p">{</span>
    <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">bucket</span><span class="p">.</span><span class="nx">id</span>

    <span class="nx">topic</span> <span class="p">{</span>
      <span class="nx">topic_arn</span>     <span class="p">=</span> <span class="nx">aws_sns_topic</span><span class="p">.</span><span class="nx">topic</span><span class="p">.</span><span class="nx">arn</span>
      <span class="nx">events</span>        <span class="p">=</span> <span class="p">[</span><span class="s2">"s3:ObjectCreated:*"</span><span class="p">]</span>
      <span class="nx">filter_suffix</span> <span class="p">=</span> <span class="s2">".log"</span>
    <span class="p">}</span>
  <span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <p><strong>Metrics</strong> Monitors and records overall metrics related to the S3 bucket. Can be customized to monitor the entire bucket or can be set to specific filters.</p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/metrics-configurations.html" rel="external nofollow noopener" target="_blank">Related AWS Doc.</a></p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># For the entire S3 bucket</span>
  <span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"example"</span> <span class="p">{</span>
    <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"example"</span>
  <span class="p">}</span>

  <span class="k">resource</span> <span class="s2">"aws_s3_bucket_metric"</span> <span class="s2">"example-entire-bucket"</span> <span class="p">{</span>
    <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">example</span><span class="p">.</span><span class="nx">id</span>
    <span class="nx">name</span>   <span class="p">=</span> <span class="s2">"EntireBucket"</span>
  <span class="p">}</span>

  <span class="c1"># With filters</span>
  <span class="k">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"example"</span> <span class="p">{</span>
    <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"example"</span>
  <span class="p">}</span>

  <span class="k">resource</span> <span class="s2">"aws_s3_bucket_metric"</span> <span class="s2">"example-filtered"</span> <span class="p">{</span>
    <span class="nx">bucket</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">example</span><span class="p">.</span><span class="nx">id</span>
    <span class="nx">name</span>   <span class="p">=</span> <span class="s2">"ImportantBlueDocuments"</span>

    <span class="nx">filter</span> <span class="p">{</span>
      <span class="nx">prefix</span> <span class="p">=</span> <span class="s2">"documents/"</span>

      <span class="nx">tags</span> <span class="p">=</span> <span class="p">{</span>
        <span class="nx">priority</span> <span class="p">=</span> <span class="s2">"high"</span>
        <span class="nx">class</span>    <span class="p">=</span> <span class="s2">"blue"</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <h3 id="cost-planning-and-optimization">Cost planning and optimization</h3> <p>It is important to keep an eye on costs, especially when handling Terabytes or Petabytes of data in your Data Lake. The first step to manage costs is to monitor it. One of the many ways to monitor costs in AWS is the <a href="https://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html" rel="external nofollow noopener" target="_blank">AWS Cost Explorer</a> service. Please note that there is a nominal cost to make API calls to the CE service.</p> <p>Terraform allows defining some options to define Cost Explorer resources:</p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_ce_anomaly_monitor"</span> <span class="s2">"service_monitor"</span> <span class="p">{</span>
  <span class="nx">name</span>              <span class="p">=</span> <span class="s2">"AWSServiceMonitor"</span>
  <span class="nx">monitor_type</span>      <span class="p">=</span> <span class="s2">"DIMENSIONAL"</span>
  <span class="nx">monitor_dimension</span> <span class="p">=</span> <span class="s2">"SERVICE"</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <p>Another alternative to view your spending is the comprehensive AWS <a href="https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html" rel="external nofollow noopener" target="_blank">Cost and Usage report</a>. This service allows sending data in CSV format to an S3 bucket from which you can visualize the cost data via one of the available <a href="https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html#download-cur" rel="external nofollow noopener" target="_blank">AWS reporting services</a>.</p> <p>Defining a Cost and Usage report resource via Terraform:</p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_cur_report_definition"</span> <span class="s2">"example_cur_report_definition"</span> <span class="p">{</span>
  <span class="nx">report_name</span>                <span class="p">=</span> <span class="s2">"example-cur-report-definition"</span>
  <span class="nx">time_unit</span>                  <span class="p">=</span> <span class="s2">"HOURLY"</span>
  <span class="nx">format</span>                     <span class="p">=</span> <span class="s2">"textORcsv"</span>
  <span class="nx">compression</span>                <span class="p">=</span> <span class="s2">"GZIP"</span>
  <span class="nx">additional_schema_elements</span> <span class="p">=</span> <span class="p">[</span><span class="s2">"RESOURCES"</span><span class="p">,</span> <span class="s2">"SPLIT_COST_ALLOCATION_DATA"</span><span class="p">]</span>
  <span class="nx">s3_bucket</span>                  <span class="p">=</span> <span class="s2">"example-bucket-name"</span>
  <span class="nx">s3_region</span>                  <span class="p">=</span> <span class="s2">"us-east-1"</span>
  <span class="nx">additional_artifacts</span>       <span class="p">=</span> <span class="p">[</span><span class="s2">"REDSHIFT"</span><span class="p">,</span> <span class="s2">"QUICKSIGHT"</span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div> <p><cite>– Terraform Docs.</cite></p> <p>Another way to reduce data transfer and networking costs is to keep the data closer to its source when building the data lake.</p> <p>Some options:</p> <ul> <li>Storing the data in an AWS S3 bucket belonging to the same region as the data sources.</li> <li>Analyzing data in the same region and then sending only relevant data (such as as summaries or reports etc.) across different AWS regions.</li> </ul> <p>Each service in AWS has its own pricing, so it important to note them and use them accordingly.</p> <h1 id="etl">ETL</h1> <p>There are several ETL options (both <a href="https://projects.apache.org/projects.html?category#big-data" rel="external nofollow noopener" target="_blank">open source</a> and otherwise) when it comes to building pipelines for a data lake.</p> <p>This largely depends on the use case. You can build a simple Python pipeline, or use an off-the-shelf ETL product or use one of the big data projects.</p> <p>When the data volume is large, the choice for a typical data lake is Apache Spark or Apache Flink.</p> <h2 id="batch-vs-streaming">Batch vs. Streaming</h2> <p>Again, this depends on the latency you can afford with respect to the data arriving to the data lake. If a latency is tolerable and can consume all of the data between a certain time interval, batch workflows are fine. If the data volume is large or is expected to grow over time, a streaming workflow is desirable.</p> <p>If you want near-realtime latency, again, a streaming pipeline is required.</p> <p><strong>Some design considerations:</strong></p> <ul> <li>How much latency is tolerable?</li> <li>What is your current and projected data volume? (What will be the volume in 6 months, 1 year, 5 years etc.?)</li> <li>How are you handling error records? Are they required to be reprocessed?</li> <li>How fault tolerant is your pipeline? How will the pipeline start if there is a failure? (Consume all available data again or maintain destination checkpoints). Is a restart automatic? How many times do you retry? Are there notifications about failures?</li> <li>Are you accounting for permanent data loss if you are reading from a streaming services like Kinesis? (What happens if your pipeline is not restarted beyond the retention timeline of the streaming service?)</li> <li>Are you handling de-duplication automatically?</li> <li>Are you implementing monitoring and alerting?</li> <li>Are you balancing costs vs. accuracy of the data?</li> </ul> <h1 id="monitoring-and-alerting">Monitoring and Alerting</h1> <p>It is very important for any data pipeline to maintain proper monitoring and alerting. This allows timely intervention when there are problems with the pipelines. It also allows us to preempt what could become a larger problem later on.</p> <p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html" rel="external nofollow noopener" target="_blank">AWS Cloudwatch</a> is amongst the best options available for monitoring services in AWS because it allows sending logs from any service and also allows different log storage and notification mechanisms.</p> <p>AWS also has a robust <a href="https://registry.terraform.io/modules/terraform-aws-modules/cloudwatch/aws/latest" rel="external nofollow noopener" target="_blank">Terraform module</a> to create and manage Cloudwatch resources. <a href="https://github.com/terraform-aws-modules/terraform-aws-cloudwatch/tree/master/examples/complete-log-metric-filter-and-alarm" rel="external nofollow noopener" target="_blank">Example metric filter and alarm.</a></p> <h1 id="analytics">Analytics</h1> <p>So far, we have discussed data sources, ingestion, ETL and related topics. Now, we will discuss analytics on a data lake built on AWS.</p> <p><strong>Design considerations:</strong></p> <ul> <li>What is the primary use case of analytics? Examples: downstream data transformation (ETL), data enrichment to suit certain use cases, data visualization, ML, SQL/queries powering other downstream storage or dashboards etc.</li> <li>Metadata management, data catalogs.</li> <li>Governance - accuracy of data, profiling, completeness.</li> <li>Notifications - data delays, gaps, other anomalies.</li> </ul> <p>AWS contains a <a href="https://aws.amazon.com/big-data/datalakes-and-analytics/" rel="external nofollow noopener" target="_blank">plethora of services</a> catering to all of the above analytics use cases and design choices.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/s3-analytics-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/s3-analytics-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/s3-analytics-1400.webp"></source> <img src="/assets/img/s3-analytics.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Some examples:</p> <ul> <li> <strong>Athena</strong> allows you to directly query S3 buckets using SQL.</li> <li> <strong>Redshift</strong> allows you to maintain structured data for datawarehousing and combines both storage and compute.</li> <li> <strong>Quicksight</strong> offers visualization. <strong>Tableau</strong> can be integrated with AWS and can be used for visualization use cases as well.</li> <li> <strong>DataZone</strong> for governance.</li> <li> <strong>Glue</strong> - serverless ETL, data catalog, interactive Python, PySpark notebooks, Cloudwatch integration, Data Quality, data cleansing.</li> </ul> <h1 id="conclusion">Conclusion</h1> <p>This article was an attempt to provide a reference to various AWS services to design and build a scalable, performant and cost-efficient data lake.</p> <p>These services keep getting updated with newer features from time to time, so the latest AWS documentation will give more information related to them.</p> <p>Each data lake effort has a variety of parameters such as available time, people in a team/organization, skills of the team, short term and long term goals for the project, users of the data lake, maintenance effort, operations and so on. It is important to keep these in mind while deciding on design, architecture and implementation.</p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Harish Kesava Rao. Last updated: December 30, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>