<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Deploying on-premise big data pipelines. | Harish Kesava Rao</title> <meta name="author" content="Harish Kesava Rao"> <meta name="description" content="Deploying big data pipelines in an on-premise Hadoop cluster."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="http://harishkesavarao.github.io//blog/2019/on-prem-bd/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Harish Kesava Rao</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deploying on-premise big data pipelines.</h1> <p class="post-meta">November 23, 2019</p> <p class="post-tags"> <a href="/blog/2019"> <i class="fas fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/bigdata"> <i class="fas fa-hashtag fa-sm"></i> bigdata</a>   <a href="/blog/tag/data-engineering"> <i class="fas fa-hashtag fa-sm"></i> data-engineering</a>   <a href="/blog/tag/hive"> <i class="fas fa-hashtag fa-sm"></i> hive</a>   <a href="/blog/tag/airflow"> <i class="fas fa-hashtag fa-sm"></i> airflow</a>   <a href="/blog/tag/python"> <i class="fas fa-hashtag fa-sm"></i> python</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h1"><a href="#introduction">Introduction</a></li> <li class="toc-entry toc-h1"><a href="#use-case-and-background">Use case and background</a></li> <li class="toc-entry toc-h1"><a href="#tech-stack">Tech stack</a></li> <li class="toc-entry toc-h1"><a href="#architecture">Architecture</a></li> <li class="toc-entry toc-h1"><a href="#implementation">Implementation</a></li> <li class="toc-entry toc-h1"> <a href="#design-decisions">Design decisions</a> <ul> <li class="toc-entry toc-h2"><a href="#programming-language">Programming Language</a></li> <li class="toc-entry toc-h2"><a href="#orchestration-and-workflow-management">Orchestration and workflow management</a></li> <li class="toc-entry toc-h2"><a href="#analytics">Analytics</a></li> <li class="toc-entry toc-h2"><a href="#file-formats">File formats</a></li> <li class="toc-entry toc-h2"><a href="#compute">Compute</a></li> <li class="toc-entry toc-h2"><a href="#storage">Storage</a></li> <li class="toc-entry toc-h2"><a href="#cicd">CI/CD</a></li> <li class="toc-entry toc-h2"><a href="#consumption-and-analytics">Consumption and analytics</a></li> </ul> </li> <li class="toc-entry toc-h1"> <a href="#learning">Learning</a> <ul> <li class="toc-entry toc-h2"><a href="#performance">Performance</a></li> <li class="toc-entry toc-h2"> <a href="#improvements">Improvements</a> <ul> <li class="toc-entry toc-h3"><a href="#some-future-improvements">Some future improvements:</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#moving-to-the-cloud">Moving to the cloud</a></li> </ul> </li> <li class="toc-entry toc-h1"><a href="#conclusion">Conclusion</a></li> </ul> </div> <hr> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>This post is about a big data deployment we (myself and a few others in my company) did a few years ago. This was a time when only a few companies were cloud-first. Some of them hadn’t ventured into the cloud at all and cloud adoption (mainly AWS at the time) was divided into part on-premise/part cloud to completely on-premise.</p> <p>This makes for some interesting choices for the tech stack. For instance, compute and storage had to be carefully managed. Permissions had to be manually handled as well.</p> <h1 id="use-case-and-background">Use case and background</h1> <p>Prior to this exercise, most of our datawarehouse was on Postgres (again an on-premise deployment). That worked for a few years until the data volume grew from GB/week or month to TB/month or GB/day or week. We had to start exploring alternatives which were:</p> <ol> <li>Scalable.</li> <li>Maintainable.</li> <li>Performant for the volume of data.</li> <li>Aligned with the overall stack being used by the company at the time.</li> <li>Proven to be effective via a Proof Of Concept.</li> </ol> <p>After exploring many such alternatives and discussions with teams having similar use cases, we decided on the following:</p> <h1 id="tech-stack">Tech stack</h1> <p><em>Almost</em> all the tools/technology used are Open Source, except the Hadoop cluster, deployed via Cloudera.</p> <table> <thead> <tr> <th>Area</th> <th>Tools/technology</th> </tr> </thead> <tbody> <tr> <td>Compute</td> <td>Hadoop</td> </tr> <tr> <td>Storage</td> <td>HDFS</td> </tr> <tr> <td>Orchestration, workflow management</td> <td>Apache Airflow</td> </tr> <tr> <td>Containerization</td> <td>Docker (published to GitLab container registry)</td> </tr> <tr> <td>Programming Language</td> <td>Python 2.7 at the time and later 3.x, PySpark</td> </tr> <tr> <td>Analytics/data presentation layer</td> <td>Presto on Apache Hive with Spark compute (wrapper on Apache Hive)</td> </tr> <tr> <td>CI/CD</td> <td>Custom-built Airflow operators</td> </tr> </tbody> </table> <h1 id="architecture">Architecture</h1> <p>The diagram below shows an overall architecture. We had two data sources, both of them housing fairly large amount of data - in the order of gigabytes per week to petabytes on a monthly basis.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/on-prem-bd-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/on-prem-bd-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/on-prem-bd-1400.webp"></source> <img src="/assets/img/on-prem-bd.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h1 id="implementation">Implementation</h1> <p>The implementation contains the following components:</p> <p>From a <strong>Data Engineering</strong> perspective:</p> <ul> <li>Reading from the data sources.</li> <li>Transforming the data.</li> <li>Creating appropriate destination data structures (Apache Hive tables).</li> <li>Loading the data.</li> <li>Backfills, fault tolerance of the data pipeline.</li> <li>Alerting - for workflow/job failures or upstream dependency problems.</li> </ul> <p>From a <strong>Data Infrastructure</strong> perspective:</p> <ul> <li>Managing code versions.</li> <li>Handling dependencies (and its versions) required for the code to run.</li> <li>Deploying code changes.</li> <li>Permissions.</li> </ul> <h1 id="design-decisions">Design decisions</h1> <h2 id="programming-language">Programming Language</h2> <blockquote> <p>Python/PySpark.</p> </blockquote> <p>Spark API is available in 4 langauges: Scala, Python, Java, R. Of these, Scala and Python were the top contenders, since Java was a new language for our tech stack and offered little unique advantages compared to Python and Scala.</p> <p>The trade-offs between Scala and Python:</p> <ul> <li> <strong>Spark performance:</strong> - although Spark offers APIS in Python and Scala, the initial versions of the Python API was not as performant as the Scala API. However, later versions of the Python API caught up with the Scala API’s performance.</li> <li> <strong>Ease of use:</strong> Did we have enough knowledge within the team to use Scala comfortably? Is it worth maintaining one project in Scala whilst all the other projects have historically been in Python?</li> <li> <strong>Maintenance:</strong> How easy is it to maintain code? How are dependencies managed?</li> <li> <strong>Learning curve with Scala</strong> - since Python was our primary language, some of us had to pick up Scala as new programming language, which added to the complexity.</li> </ul> <p>To explore the above items, we performed small Proof Of Concept exercises, such as:</p> <ul> <li>Benchmarking API performance between Scala and Python.</li> <li>Building dependencies in Scala using sbt vs. pip in Python.</li> </ul> <h2 id="orchestration-and-workflow-management">Orchestration and workflow management</h2> <blockquote> <p>Apache Airflow</p> </blockquote> <p>Task management, scheduling and other actions had to be managed. Apache Airflow, hosted with a Postgres backend was already available. We chose to use it.</p> <p>Airflow did not have all the operators we required. So, we ended up writing custom operators for the following:</p> <ul> <li>Python (running Python scripts)</li> <li>Apache Hive (running queries on Apache Hive)</li> <li>Shell operator (executing bash or other shell commands)</li> <li>Docker operator (running Docker commands)</li> </ul> <h2 id="analytics">Analytics</h2> <blockquote> <p>Apache Hive/Presto</p> </blockquote> <p>Thinking beyond the data pipelines, the decisions related to data consumption came about.</p> <p>Some options were:</p> <ul> <li>Apache Hive -&gt; Postgres -&gt; Tableau/Queries/Jupyter notebooks.</li> <li>Apache Hive -&gt; Presto -&gt; Tableau(using Presto connector)/Jupyter notebooks.</li> </ul> <h2 id="file-formats">File formats</h2> <blockquote> <p>Parquet.</p> </blockquote> <p>Options:</p> <ul> <li>JSON.</li> <li>CSV.</li> <li>Parquet.</li> <li>ORC.</li> </ul> <p><strong><em>Reasons:</em></strong> Compression options, schema evolution, partition discovery, columnar storage and encryption and overall better performance.</p> <h2 id="compute">Compute</h2> <p>A shared Hadoop cluster was already available and only permissions had to be created to access the cluster.</p> <h2 id="storage">Storage</h2> <p>Straightforward HDFS storage with a Apache Hive metastore. We created a new Apache Hive metastore for our project since the entire storage was shared.</p> <h2 id="cicd">CI/CD</h2> <p>We used GitLab for the following:</p> <ol> <li>Code versions.</li> <li>Publishing docker image versions to GitLab container registry.</li> <li>Running pytest checks.</li> </ol> <h2 id="consumption-and-analytics">Consumption and analytics</h2> <p>Now that we have discussed the ingestion pipeline, the next step is making the datasets available for users.</p> <p>Since we are dealing with large data volumes, querying Apache Hive directly wasn’t scalable (via Presto). We used Presto on Spark.</p> <p>Analytics was done on a Jupyter notebook, so the query results were used to build visualizations.</p> <p>Analytics teams built their own DAGs using the datasets we created.</p> <h1 id="learning">Learning</h1> <h2 id="performance">Performance</h2> <p>The Hadoop cluster was performant to ingest data at the rate we expected. The query response time was dependent on the partitioning of the Apache Hive table.</p> <h2 id="improvements">Improvements</h2> <h3 id="some-future-improvements">Some future improvements:</h3> <ul> <li>Managing Python dependencies/packaging better using npm.</li> <li>Creating leaner docker images to improve deployment times.</li> <li>Moving away from Apache Hive (see the section on Moving to the cloud).</li> </ul> <h2 id="moving-to-the-cloud">Moving to the cloud</h2> <p>When the migration to the cloud was started, the following changes were made to the architecture:</p> <table> <thead> <tr> <th>Type</th> <th>On-premise</th> <th>Cloud</th> </tr> </thead> <tbody> <tr> <td>Query Engine</td> <td>Hive</td> <td>Snowflake</td> </tr> <tr> <td>Storage</td> <td>HDFS</td> <td>AWS S3</td> </tr> <tr> <td>Compute</td> <td>Hadoop</td> <td>AWS EMR, EC2</td> </tr> <tr> <td>CI/CD</td> <td>Gitlab CI</td> <td>AWS Codebuild</td> </tr> <tr> <td>Docker registry</td> <td>GitLab container registry</td> <td>AWS ECR</td> </tr> <tr> <td>Orchestration, workflow management</td> <td>Apache Airflow</td> <td>Amazon Managed Workflows for Apache Airflow (MWAA)</td> </tr> <tr> <td>Permissions</td> <td>Manual</td> <td>AWS IAM</td> </tr> </tbody> </table> <hr> <h1 id="conclusion">Conclusion</h1> <p>Overall, the project helped us foray into the big data area and keep up with current and future data needs of the organization.</p> <p>The cloud allowed us to scale and automate many of the steps for development, deployment and maintenance.</p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Harish Kesava Rao. Last updated: December 21, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>